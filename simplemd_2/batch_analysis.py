from contextlib import contextmanager
import sys, os, contextlib, time, copy
import matplotlib.pyplot as plt
from matplotlib import rc, gridspec
import numpy as np
import pandas as pd
from simplemd_2.utils import format_to_tex, get_colorlist, boil_down_to_minmaxmean, check_up_ipython, format_to_pandas
from datetime import datetime


def measure_times(main_settings, variable_settings, sim_func, 
                  silent_mode=False, repeats=3, plot=True, 
                  save_potentials=False, save_md_data=False, save_time_data=False):  
    
    assert type(variable_settings) == dict
    
    all_times = list()
    total_number = get_total_number(variable_settings)
    computation_counter = 0
    
    if save_potentials is True:
        now = datetime.now()
        str_now = now.strftime('%Y-%m-%d_%H-%M')
        img_dirname = "batch_"+str_now+"_images"

        try:
            os.mkdir(img_dirname)
        except:
            pass
        
        main_settings['cutoff'].update({"plot":True})
    
    if save_md_data is True:
        from shutil import copyfile
        import json
        from .io import save_settings_to_json
        
        copied_filenames = ["positions.xyz", "velocities.xyz", "key_positions.xyz", "energy.txt"]
        save_settings_to = "settings.json"
        
        save_default_settings_to = "default_settings.json"
        save_variable_settings_to = "variable_settings.json"
        
        now = datetime.now()
        str_now = now.strftime('%Y-%m-%d_%H-%M')
        md_dirname = "batch_"+str_now+"_mds"

        try:
            os.mkdir(md_dirname)
        except:
            pass
        
        save_settings_to_json(variable_settings, os.path.join(md_dirname, save_variable_settings_to))
        save_settings_to_json(main_settings, os.path.join(md_dirname, save_default_settings_to))
        main_settings['cutoff'].update({"plot":True})
    
    for id1, (key1, item_list1) in enumerate(variable_settings.items()):
        for id2, (key2, item_list2) in enumerate(variable_settings.items()):
            if key1 == key2 or id2 < id1:
                continue
                
            for item1 in item_list1:
                for item2 in item_list2:
                    st = main_settings.copy()  
                    
                    key1 = key1.strip("_")
                    key2 = key2.strip("_")
                    
                    if type(item1) == dict:
                        st[key1].update(item1)
                        lab1 = key1 + "_" + list(item1.keys())[0]
                        val1 = list(item1.values())[0]

                    else:
                        st[key1] = item1
                        lab1 = key1
                        val1 = item1
                    
                    if type(item2) == dict:
                        st[key2].update(item2)
                        lab2 = key2 + "_" + list(item2.keys())[0]
                        val2 = list(item2.values())[0]
                        
                    else:
                        st[key2] = item2
                        lab2 = key2
                        val2 = item2

                    time12 = [(lab1, val1), (lab2, val2)]
                    
                    computation_counter += 1
                    print("Running configuration ", computation_counter, "/", total_number, " ...  ", item1," ; ", item2)
                    
                    for i in range(repeats):                       
                        if silent_mode is True:
                            mngr = suppress_stdout()
                        else:
                            mngr = contextlib.nullcontext()
                            
                        with mngr:
                            t1 = time.time()
                            sim_func(st)
                            t2 = time.time()
                            
                            if save_potentials is True and i == 0:
                                str_values = str(lab1)+"--"+str(val1)+"__"+str(lab2)+"--"+str(val2)
                                img_filename = "potential_"+str(computation_counter) +"__" + str_values.replace(":","_").replace(".","")+".png"
                                try:
                                    img_path = os.path.join(img_dirname, img_filename)
                                    plt.savefig(img_path)
                                except:
                                    import warnings
                                    warnings.warn("\nSaving of the "+str(computation_counter)+"th image >>"+
                                                  img_filename+"<< went wrong. "+
                                                  "\nThe autogenerated filename is probably causing this issue. "+
                                                  "This image was discarded.")
                                plt.close()
                                
                            else:
                                plt.close('all')
                            
                            if save_md_data is True: # and i == 0:
                                str_values = str(lab1)+"--"+str(val1)+"__"+str(lab2)+"--"+str(val2)
                                folder_name = "folder_"+str(computation_counter)+"__"+str_values.replace(":","_")

                                folder_path = os.path.join(md_dirname, folder_name)
                                try:
                                    os.mkdir(folder_path)
                                except:
                                    pass
                                
                                for file in copied_filenames:
                                    try:
                                        copyfile(file, os.path.join(folder_path, file.replace(".", "_"+str(i)+".")))
                                    except FileNotFoundError:
                                        pass
                                    
                                save_settings_to_json(st, os.path.join(folder_path, save_settings_to))
                            else:
                                pass
                            
                            time12.append(t2-t1)
                            
                        print("    ... run ", i+1,"/", repeats, " done")
                        
                    all_times.append(time12)
                    
    print("Everything has finished successfully!")
    
    if plot is True:
        with plt.style.context('seaborn'):
            plt.figure(figsize=(5,3), dpi=300)
            data_x = np.arange(0, repeats, 1.0)+1

            lines = list()

            for config in all_times:
                lines.append(plt.plot(data_x, config[2:], label= str(config[:2]))[0])

            plt.legend(handles=lines, fontsize=8, bbox_to_anchor=(0.5, 1.03), loc='lower center', frameon=False )
            plt.xlabel("repeats")
            plt.ylabel("time [s]")  
            plt.xticks(data_x)

            plt.show()
    
    data_pd = format_to_pandas(all_times)
        
    if save_time_data is True:          
        time_filename = "runtime_data.csv"
        data_pd.to_csv(time_filename)
        
        if save_md_data is True:
            copyfile(time_filename, os.path.join(md_dirname, time_filename))

    return data_pd, md_dirname

  
## silencing context manager
@contextmanager
def suppress_stdout():
    with open(os.devnull, "w") as devnull:
        old_stdout = sys.stdout
        sys.stdout = devnull
        try:  
            yield
        finally:
            sys.stdout = old_stdout


# function calculates the total number of pairs to be evaluated in the simulation 
def get_total_number(dct):
    lst = [len(x) for x in dct.values()]
    total = 0
    for i,j in enumerate(lst):
        for m in lst[i+1:]:
            total += j*m
            
    return total
   
    
# function reads all targeted energy files and creates a dataframe including each time frame  
def format_energy_files_to_pandas(folder_path, common_fn, columns=None, labels=None, mean=True):
    import pandas as pd
    from .io import read_energy_file
    
    if labels is None:
        labels = ['step', 'time', 'E_kin', 'E_pot', 'E_tot', 'T_kin']
        
    if columns is None:
        columns = labels[1:]  # i.e. all columns, time on x-axis
    
    to_pandas = pd.DataFrame()
    
    for path, subdirs, files in os.walk(folder_path):
        if "batch" in path and "folder" in path:
            stack = dict.fromkeys(columns[1:], np.array([]))

            for name in files:
                if common_fn in name:
                    fpath = os.path.join(path, name)
                    label = path.split("folder_")[1]
                    file_data = read_energy_file(fpath, labels)

                    for column in columns[1:]:
                        if len(stack[column]) == 0:
                            stack[column] = file_data[columns[0]]

                        stack[column] = np.vstack((stack[column], file_data[column]))       

            if mean is True:
                stack = { key: np.vstack((val[0,:], np.mean(val[1:,:], axis=0))) for key, val in stack.items()}

            folder_data = np.array([ [np.array([label, key, axis, *array]) 
                             for (axis, array) in zip(['x', *np.repeat('y', len(val)-1)], val)] for (key, val) in stack.items()])
            dims = folder_data.shape
            reshaped_data = np.reshape(folder_data, (dims[0]*dims[1], dims[2] ) )
            index = reshaped_data[:,:3]
            df_index = pd.DataFrame(index, columns=["folder", "E", "axis"])
            multi_index = pd.MultiIndex.from_frame(df_index)
            folder_dataframe = pd.DataFrame(reshaped_data[:,3:], index=multi_index, dtype=np.float64)

            if len(to_pandas) == 0:
                to_pandas = folder_dataframe
            else:
                to_pandas = pd.concat([to_pandas, folder_dataframe])
                
    if len(to_pandas) == 0:
        raise Exception("Something went wrong. No data were loaded. Check the format of entered folder path.")
    
    return to_pandas.swaplevel(0,1).sort_index()
    

# plot energy evolution from each file
def plot_energy_from_pandas(dataframe, xlim_max=None, ylimits=None, lvl0_order=None,
                            hide_bottom_label=False, legend_linewidth=2.0, 
                            display_means=False, area_alpha=0.08,
                            linewidth=1.0, fontsize=13, figsize=(10,10), dpi=350, legend_font_size = 13, hspace=0.0,
                            savefig=None,
                            **kwargs,
                           ):

    plt.rcParams.update({"text.usetex": True, 'font.size': fontsize})
    rc('text.latex', preamble=r'\usepackage{amsmath} \usepackage[utf8]{inputenc}' )
    plt.rcParams['xtick.bottom'] = plt.rcParams['xtick.labelbottom'] = True
    plt.rcParams['xtick.top'] = plt.rcParams['xtick.labeltop'] = False

    lvl0_labels = dataframe.index.levels[0]
    lvl1_labels = dataframe.index.levels[1]
    
    if lvl0_order is not None:
        lvl0_labels = lvl0_labels[list(lvl0_order)]

    fig, ax = plt.subplots(num=None, figsize=figsize, dpi=dpi, facecolor='w', edgecolor='k')
    gs = gridspec.GridSpec(ncols=1, nrows=lvl0_labels.size, figure=fig) 

    axes = dict()

    #default_colors = plt.rcParams['axes.prop_cycle'].by_key()['color']
    colorlist = get_colorlist(lvl1_labels.size)
    
    for i, lvl0_label in enumerate(lvl0_labels):
        if i == 0:
            axes[lvl0_label] = plt.subplot(gs[i])
            x_owner = axes[lvl0_label]

        else:
            axes[lvl0_label] = plt.subplot(gs[i], sharex=x_owner)

        graph = axes[lvl0_label]  
        center_y = list()
        max_x = list()

        for (color, lvl1_label) in zip(colorlist, lvl1_labels):
            selection = dataframe.loc[lvl0_label, lvl1_label]
            
            if display_means is True:
                ydata_max, ydata_min, ydata_mean = boil_down_to_minmaxmean(selection)
                x = np.array(selection.iloc[0,:])
                graph.fill_between(x, ydata_max, ydata_min, facecolor=color, alpha=area_alpha)
                graph.plot(x, ydata_mean, label= lvl1_label, 
                           linewidth=linewidth, color=color, **kwargs)
                max_x.append(x[-1])
                center_y.append(ydata_mean[0])
            
            else:
                plottable = np.array([[selection.iloc[0,:], selection.iloc[m,:]] for m in range(1, selection.index.values.size)])

                for x, y in plottable:
                    graph.plot(x, y, label= lvl1_label,
                               linewidth=linewidth, color=color, **kwargs)
                    center_y.append(y[0])
                    max_x.append(x[-1])

        # enable custom ylim scaling ... otherwise set default values        
        if type(ylimits) == dict and lvl0_label in ylimits.keys():
            lmt = ylimits[lvl0_label]                
            
            if type(lmt) == tuple:
                ylim = lmt
            else:
                scale = lmt
                limit_y = np.array(center_y).mean() * scale
                ylim = np.sort((0, limit_y))
        else:
            scale = 2 if lvl0_label == 'E_tot' else 6
            limit_y = np.array(center_y).mean() * scale
            ylim = np.sort((0, limit_y))

        if xlim_max is None:
            xlim_max = max(max_x)
        else:
            pass

        graph.set_ylim(ylim)
        graph.set_xlim((0, xlim_max))
        graph.set_ylabel(format_to_tex(lvl0_label, retain_underscore=True))

        if i != len(lvl0_labels)-1:
            plt.setp(axes[lvl0_label].get_xticklabels(), visible=False)
            plt.setp(axes[lvl0_label].get_xticklines(), visible=False)
            yticks = axes[lvl0_label].yaxis.get_major_ticks()
            
            if hide_bottom_label is True:
                yticks[0].label1.set_visible(False)

        else:
            axes[lvl0_label].set_xlabel(format_to_tex('time \:[ns]'))

    def sort_legend(tup):
        h, l = tup
        return int(l.split("_",1)[0])
    
    # based on: https://stackoverflow.com/questions/26337493/pyplot-combine-multiple-line-labels-in-legend
    handles, labels = plt.gca().get_legend_handles_labels()
    newLabels, newHandles = list(), list()
    for handle, label in sorted(zip(handles, labels), key=sort_legend):
        if label not in newLabels:
            newLabels.append(label)         
            handle = copy.copy(handle)
            handle.set_linewidth(legend_linewidth)
            newHandles.append(handle)
    newLabels = [format_to_tex(label) for label in newLabels]

    plt.legend(newHandles, newLabels,
               frameon=False, loc="lower center", 
               ncol=2, borderaxespad=0.0, 
               prop={'size': legend_font_size},
               bbox_transform=plt.gcf().transFigure,
               bbox_to_anchor=(0.5,0.9),
              )

    plt.subplots_adjust(hspace=hspace)
    
    if type(savefig) == str:
        from .utils import file_saver        
        path = file_saver(savefig)        
        plt.savefig(path, dpi=dpi, bbox_inches='tight')
    
    use_ipy_feat = check_up_ipython()
    
    if savefig is not None and use_ipy_feat is False:
        pass
    else:
        plt.show()


# reads all targeted xyz files and creates a dataframe including all time frames
def get_rdf_to_pandas(folder_path, common_fn, rho=None, box=None, save_to_csv=True, give_dataframe=False,
                      time_instead_of_steps=True, ):

    from .utils import file_saver, write_csv_with_comments
    
    assert any([save_to_csv, give_dataframe]), 'No output is selected. Please do so ...'
    
    data = pd.DataFrame()
    nfiles = list()
    frame_key = 'time' if time_instead_of_steps else 'step'   
    
    print("This process is going to take some time ...")    
    print_done = " ... done in {:.2f} s\n"

    print_stack = "Evaluating files ..."
    print(print_stack)
    time0 = time.time()
    
    for path, subdirs, files in os.walk(folder_path):
        if "batch" in path and "folder" in path:
            folder_data = None
            nfiles.append(0)
            
            for name in files:
                if name.startswith(common_fn):
                    nfiles[-1] += 1
                    fpath = os.path.join(path, name)
                    
                    file_data, box, N = get_distances_for_rdf(fpath, box=box, rho=rho,
                                                              time_instead_of_steps=time_instead_of_steps,)
                    
                    if folder_data is None:
                        folder_data = file_data
                        
                    else:
                        folder_data = pd.concat([folder_data, file_data], axis=0, ignore_index=True)
                        
            if folder_data is not None:
                label = path.split("folder_")[1]

                multiindex = pd.MultiIndex.from_product([[label], folder_data.columns], names=['file', frame_key])
                folder_data = folder_data.reindex(columns=multiindex, level=1, copy=False)
                data = pd.concat([data, folder_data], axis=1)
    
    dt = time.time() - time0
    print(print_done.format(dt))
    
    n = max(nfiles)
    
    time1 = time.time()
    print_stack = "Transposing and sorting data ..."
    print(print_stack)
    
    out = data.T
    
    # sort dataframe by index
    def sort_indices(index):
        import pandas as pd
        new = [int(x.split('_', 1)[0]) for x in index]
        return pd.Index(new, name=index.name)
    
    out.sort_index(level=0, axis=0, key=sort_indices, inplace=True)
    
    time2 = time.time() 
    dt = time2 - time1
    print(print_done.format(dt))  
    
    output_filename = "distances_for_multi_rdf"
    extension = ".csv"
    number = 0
    
    comments = {'box':box, 'repeats':n, 'N':N, 'shape':out.shape, 'rho':rho, 'folder':folder_path, 'frame_key':frame_key }
    
    if save_to_csv is True:
        pth = os.path.join(folder_path, output_filename+extension)
        output_path = file_saver(pth)
        
        time1 = time.time()
        print_stack = "Saving data ..."
        print(print_stack)
        
        write_csv_with_comments(output_path, out, comments)
        
        time2 = time.time() 
        dt = time2 - time1
        
        print(print_done.format(dt))
    
    print("Done in {:.2f} s".format(time2 - time0))
            
    if give_dataframe is True:
        return out, comments


# helper function calculating the distances in files
def get_distances_for_rdf(filepath, rho=None, box=None, time_instead_of_steps=True):
    
    from simplemd_2.io import read_xyz_frame
    import re
    
    re_step = re.compile("step\s\d+")
    re_time = re.compile("time\s[\d.]+")
    
    data = None
    frame_counter = 0
    rho0 = True if rho is not None and frame_counter == 0 else False
    
    with open(filepath, 'r') as file:
        while True:
            frame = read_xyz_frame(file)
            
            if not frame:
                break
            
            calc_box = False
            calc_rho = False
            
            if rho is None and box is None:
                calc_box = True
                calc_rho = True
            elif box is not None and rho0 is False:
                calc_rho = True
            elif rho is not None:
                calc_box = True
            else:
                pass
            
            frame_counter += 1
            
            step = int(re_step.findall(frame[0])[0][5:])
            time = float(re_time.findall(frame[0])[0][5:])
            x = frame[2]
            N = len(x)
            dx = x[:,np.newaxis,:] - x[np.newaxis,:,:]

            if calc_box is True:
                if rho is not None:
                    box_L = np.cbrt(N / rho)
                    box = ([box_L]*3)
                    calc_box = False
                elif box is None:
                    box = np.full(3, np.max(x))
                elif np.max(x) > np.max(box):
                    box = np.full(3, np.max(x))
                    
            if calc_rho is True:
                rho = N / box[0]**3
                if calc_box is False:
                    calc_rho = False
                    
            dx -= box * np.round(dx / box)
            d = np.sqrt((dx**2).sum(axis=2))
            dd = np.triu(d).flatten()
            frame_key = time if time_instead_of_steps else step
            
            if data is None:
                data = pd.DataFrame.from_dict({frame_key: dd[dd != 0]})
            else:
                new = pd.DataFrame.from_dict({frame_key: dd[dd != 0]})
                data = data.join(new)
    
    return data, box, N 



def multi_rdf_from_pandas(file, dr=0.15, load_last=False, comments=None,
                          frame_start=100, frame_end=None,):
    
    import warnings
    from .utils import read_csv_comments, write_csv_with_comments
    
    # check iPython environment
    use_ipy_feat = True
    try:
        from IPython.display import clear_output
    except ModuleNotFoundError:
        use_ipy_feat = False
        pass
    except ImportError:
        use_ipy_feat = False
        pass
    
    lastcall_filename = 'lastcall_rdf_data.csv'
    
    time1 = time.time()
    print('Initializing ...')
    
    if load_last is True:
        folder = os.path.split(file)[0] if file.endswith('.csv') else file
        pt = os.path.join(folder, lastcall_filename)
        comments = read_csv_comments(pt)
        dataframe = pd.read_csv(pt, header=[0], index_col=[0], comment='#')
        out = dataframe.to_dict('list')
        xaxis = np.array(out.pop('xaxis'))
        print("Loading from lastcall file done ...")
        
        return xaxis, out, comments
    
    if type(file) == str and file.endswith('.csv'):
        comments = read_csv_comments(file)
    else:
        assert comments is not None  
    
    cs = comments
    box = cs['box']
    rho = cs['rho']
    repeats = cs['repeats']
    N = cs['N']
    shape = cs['shape']
    frame_key = cs['frame_key']

    xaxis = np.arange(0, box[0]/2.0, dr)
    out = dict()
    data = np.zeros_like(xaxis)

    V_shell = 4.0 / 3.0 * np.pi * ((xaxis+dr)**3 - xaxis**3)
    frame_counter = 0
    label0 = None
    
    if type(file) == str and file.endswith('.csv'):
        with warnings.catch_warnings():
            warnings.simplefilter("ignore")
            
            level1_type = np.float16 if frame_key == 'time' else np.int32

            csv_reader = pd.read_csv(file, header=[0], index_col=[0,1],
                                     comment='#',
                                     iterator=True, chunksize=100,
                                     dtype=np.float16, converters={0: str, 1: level1_type})

            out = dict()

            for chunk in csv_reader:
                for (label, fkey), line in chunk.iterrows():
                    if fkey < frame_start:
                        continue
                    if frame_end is not None and fkey >= frame_end:
                        continue

                    clear_output(wait=True)
                    #print('step: '+str(fkey), label +'\r')
                    print('{keylab}: {fkey}, {label} \r'.format(keylab=frame_key, fkey=fkey, label=label))
                    frame_counter += 1

                    for i, r in enumerate(xaxis):
                        n = np.where((line <= r+dr) & (line > r), 1, 0).sum()
                        data[i] += 2 * n / V_shell[i]

                    if label != label0:
                        data /= frame_counter * N * rho * repeats
                        frame_counter = 0
                        out[label] = data
                        data = np.zeros_like(xaxis)

                    label0 = label
                    
    else:
        for (label, fkey), line in file.iterrows():
            if fkey < frame_start:
                continue
            if frame_end is not None and fkey >= frame_end:
                continue

            if use_ipy_feat:
                clear_output(wait=True)
                #print('step: '+str(fkey), label +'\r')
                print('{keylab}: {fkey}, {label} \r'.format(keylab=frame_key, fkey=fkey, label=label))
                
            frame_counter += 1

            for i, r in enumerate(xaxis):
                n = np.where((line <= r+dr) & (line > r), 1, 0).sum()
                data[i] += 2 * n / V_shell[i]

            if label != label0:
                data /= frame_counter * N * rho * repeats
                frame_counter = 0
                out[label] = data
                data = np.zeros_like(xaxis)

            label0 = label  
    
    dt = time.time() - time1
    print("Done in {:.2f} s".format(dt))
    
    out_path = os.path.join(comments['folder'], lastcall_filename)
    dd = out.copy()
    dd.update({'xaxis':xaxis})
    out_data = pd.DataFrame.from_dict(dd)
    write_csv_with_comments(out_path, out_data, comments)

    return xaxis, out, comments



def plot_multi_rdf(xaxis, data, box,
                   step_function=False, smooth_function=False, legend_linewidth=2.0,
                   ylim_max=None, fontsize=13, figsize=(10,5), dpi=350, legend_font_size = 13,
                   savefig=None,
                   **kwargs):
    
    if not any([smooth_function, step_function]):
        step_function = True
    
    plt.rcParams.update({"text.usetex": True, 'font.size': fontsize})
    rc('text.latex', preamble=r'\usepackage{amsmath} \usepackage[utf8]{inputenc}' )
    plt.rcParams['xtick.bottom'] = plt.rcParams['xtick.labelbottom'] = True
    plt.rcParams['xtick.top'] = plt.rcParams['xtick.labeltop'] = False
    
    fig, ax = plt.subplots(num=None, figsize=figsize, dpi=dpi, facecolor='w', edgecolor='k')
    
    colorlist = get_colorlist(len(data))

    for i, (key, val) in enumerate(data.items()):
        if step_function is True:
            plt.step(xaxis, val, label=key, color=colorlist[i], **kwargs)
            
        elif smooth_function is True:
            from scipy.interpolate import make_interp_spline
            spline = make_interp_spline(xaxis, val)
            new_xaxis = np.linspace(xaxis.min(), xaxis.max(), 500)
            plt.plot(new_xaxis, interp(new_xaxis), label=key, color=colorlist[i], **kwargs)
            
        else:
            plt.plot(xaxis, val, label=key, color=colorlist[i], **kwargs)

    plt.xlabel(format_to_tex("radius")+"$\,\\left[ 1/ \sigma \\right]$")
    plt.ylabel(format_to_tex("RDF"))
    if ylim_max is not None:
        plt.ylim(0, ylim_max)
    plt.xlim(0, min(box)/2 )
    
    def sort_legend(tup):
        h, l = tup
        return int(l.split("_",1)[0])
    
    # based on: https://stackoverflow.com/questions/26337493/pyplot-combine-multiple-line-labels-in-legend
    handles, labels = plt.gca().get_legend_handles_labels()
    newLabels, newHandles = list(), list()
    for handle, label in sorted(zip(handles, labels), key=sort_legend):
        if label not in newLabels:
            newLabels.append(label)         
            handle = copy.copy(handle)
            handle.set_linewidth(legend_linewidth)
            newHandles.append(handle)
    newLabels = [format_to_tex(label) for label in newLabels]
    
    plt.legend(newHandles, newLabels,
               frameon=False, loc="lower center", ncol=2, bbox_to_anchor=(0.5, 0.9), borderaxespad=0.0, 
               bbox_transform=plt.gcf().transFigure, prop={'size': legend_font_size},
              )
    
    if type(savefig) == str:
        from .utils import file_saver
        path = file_saver(savefig)
        plt.savefig(path, dpi=dpi, bbox_inches='tight')
    
    use_ipy_feat = check_up_ipython()
    
    if savefig is not None and use_ipy_feat is False:
        pass
    else:
        plt.show()

    
def get_multi_rdf(path, dr, rho, frame_start=0, frame_end=None, save_to_csv=False, figsize=(10,10), 
                  time_instead_of_steps=True):
    
    position_filename = "positions"
    dtfrm, comments = get_rdf_to_pandas(path, position_filename, 
                                        rho=rho, give_dataframe=True, save_to_csv=save_to_csv,
                                        time_instead_of_steps=time_instead_of_steps,)
    
    xaxis, data, comments = multi_rdf_from_pandas(dtfrm, dr, frame_start=frame_start, frame_end=frame_end, 
                                                  load_last=False, comments=comments, figsize=figsize,)
    
    return xaxis, data, comments


def load_multi_rdf(path):
    xaxis, data, comments = multi_rdf_from_pandas(path, load_last=True)
    print(comments)
    
    return xaxis, data, comments
    
    
    
def plot_runtimes(folder, filename="runtime_data.csv", dpi=300, figsize=(8,5), fontsize=13, 
                  alpha=0.7, width=0.8, switch=1, yscale='linear',
                  savefig=None,
                 ):

    from matplotlib.ticker import AutoMinorLocator 
    
    filepath = os.path.join(folder, filename)
    
    imported_data = pd.read_csv(filepath, header=0, index_col=[0,1])

    level_list = imported_data.index.levels
    lengths = np.array([len(i) for i in level_list])
    new_order = np.argsort(lengths)[::switch]
    sorted_data = imported_data.sort_index(level=[new_order[1],])
    data = sorted_data.reorder_levels(new_order[::-1])
    
    level0_labels = data.index.levels[0]
    level1_labels = data.index.levels[1]
    
    colorlist = get_colorlist(lengths.min())

    extreme = [x(lengths) for x in [np.min, np.max]][::switch]
    n, m = extreme
    maxpos = (n+1)* m
    ticks = list(range(1, maxpos))
    xticks = list()
    xticks_lab = list()

    plt.rcParams.update({"text.usetex": True, 'font.size': fontsize})
    rc('text.latex', preamble=r'\usepackage{amsmath} \usepackage{physics} \usepackage[utf8]{inputenc}' )

    plt.rcParams['xtick.bottom'] = plt.rcParams['xtick.labelbottom'] = True
    plt.rcParams['xtick.top'] = plt.rcParams['xtick.labeltop'] = False

    fig, ax = plt.subplots(num=None, figsize=figsize, dpi=dpi, facecolor='w', edgecolor='k')

    for i, key in enumerate(level0_labels):
        dd = data.loc[key]

        tickpos = i*(n+1) + (n+1)/2
        xticks.append(tickpos)
        xticks_lab.append(format_to_tex(key))
        posi = ticks[i*(n+1):(i+1)*(n+1)-1]

        bp = plt.boxplot(dd.to_numpy().T, positions = posi, widths=width, patch_artist=True)
        plt.setp(bp['medians'], color='black')

        for j in range(dd.shape[0]):
            plt.setp(bp['boxes'][j], facecolor=colorlist[j], edgecolor='black', alpha=alpha)

    ax.set_xlim(0, maxpos)
    ax.set_xticks(xticks)
    ax.set_xticklabels(xticks_lab)

    def format_legend_label(indexing):
        labels = ["{key}={value}".format(key=indexing.name, value=i) for i in indexing.values]
        return labels

    plt.yscale(yscale)
    plt.legend([bp["boxes"][l] for l in range(len(level1_labels))], 
              [format_to_tex(key) for key in format_legend_label(level1_labels)],
              frameon=False, loc="lower center", ncol=2, bbox_to_anchor=(0.53, 0.9), borderaxespad=0.0, 
              bbox_transform=plt.gcf().transFigure, columnspacing=3,
             )
    
    ax.grid(True, which='major', axis='y', alpha=0.1, linewidth=0.5)
    ax.grid(True, which='minor', axis='x', alpha=0.1, linewidth=0.5)

    for tick in ax.xaxis.get_major_ticks():
        tick.tick1line.set_markersize(0)
        tick.tick2line.set_markersize(0)
        tick.label1.set_horizontalalignment('center')
        
    minor_locator = AutoMinorLocator(2)
    ax.xaxis.set_minor_locator(minor_locator) 
    
    for tick in ax.xaxis.get_minor_ticks():
        tick.tick1line.set_markersize(5)
        tick.tick2line.set_markersize(5)
        tick.label1.set_horizontalalignment('center')
        
    ax.set_xlabel(format_to_tex(data.index.levels[0].name))
    ax.set_ylabel(format_to_tex("single simulation runtime [s]"))
    
    if type(savefig) == str:
        from .utils import file_saver
        path = file_saver(os.path.join(folder, savefig))
        plt.savefig(path, dpi=dpi, bbox_inches='tight')
    
    plt.show()
    


def plot_single_plot(dataframe, key, xlim_max=None, ylimits=None, cut_data=None,
                    legend_linewidth=2.0, plot_means=True,  
                    linewidth=1.0, fontsize=13, figsize=(10,4), dpi=350, legend_font_size = 13, hspace=0.0,
                    savefig=None,
                    **kwargs,
                   ):  

    plt.rcParams.update({"text.usetex": True, 'font.size': fontsize})
    rc('text.latex', preamble=r'\usepackage{amsmath} \usepackage{physics} \usepackage[utf8]{inputenc}' )
    plt.rcParams['xtick.bottom'] = plt.rcParams['xtick.labelbottom'] = True
    plt.rcParams['xtick.top'] = plt.rcParams['xtick.labeltop'] = False

    dat = dataframe.loc[key]
    labels = dat.index.levels[0]

    fig, ax = plt.subplots(num=None, figsize=figsize, dpi=dpi, facecolor='w', edgecolor='k')

    colorlist = get_colorlist(labels.size)

    for (color, label) in zip(colorlist, labels):
        sele = dat.loc[label]
        edge = cut_data if type(cut_data) == int else sele.index.values.size

        plottable = np.array([[sele.iloc[0,:], sele.iloc[m,:]] 
                              for m in range(1, edge )]) if not plot_means else np.array([[sele.iloc[0,:], sele.iloc[1:,:].mean(axis=0)],])

        for x, y in plottable:
            ax.plot(x, y, label= label,
                       linewidth=linewidth, color=color, **kwargs)

    ax.set_ylim(ylimits if type(ylimits) == tuple else (0,500))
    ax.set_xlim(0, xlim_max if xlim_max is not None else max(sele.iloc[0,:]) )

    def sort_legend(tup):
        h, l = tup
        return int(l.split("_",1)[0])

    phandles, plabels = ax.get_legend_handles_labels()
    newLabels, newHandles = list(), list()
    for handle, label in sorted(zip(phandles, plabels), key=sort_legend):
        if label not in newLabels:
            newLabels.append(label)         
            handle = copy.copy(handle)
            handle.set_linewidth(legend_linewidth)
            newHandles.append(handle)
    newLabels = [format_to_tex(label) for label in newLabels]

    plt.legend(newHandles, newLabels,
               frameon=False, loc="lower center", 
               ncol=2, borderaxespad=0.0, 
               prop={'size': legend_font_size},
               bbox_transform=fig.transFigure,
               bbox_to_anchor=(0.5,0.9),
              )

    ax.set_xlabel(format_to_tex('time \:[ns]'))
    ax.set_ylabel(format_to_tex(key, retain_underscore=True))

    if type(savefig) == str:
        from .utils import file_saver        
        path = file_saver(savefig)        
        plt.savefig(path, dpi=dpi, bbox_inches='tight')

    plt.show()